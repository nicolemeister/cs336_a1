Initializing vocabulary with special tokens...
Adding byte vocabulary...
Attempting to split 11368.29MB file into 16 chunks
Reading input text and finding chunk boundaries...
Input path:  /home/c-nmeist/cs336_a1/data/owt_train.txt
Found 16 valid chunk boundaries [0, 745033759, 1490070394, 2235103536, 2980128270, 3725160533, 4470223005, 5215236910, 5960269363, 6705307054, 7450321387, 8195351909, 8940385101, 9685416176, 10430448049, 11175481314, 11920511059]
Processing chunks with multiprocessing pool...
Using 16 processes
